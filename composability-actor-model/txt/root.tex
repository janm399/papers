\documentclass[10 pt, twocolumn]{article}
\input{../../common.tex}

\addbibresource{root.bib}

\title{Composability and the actor model}

\author{Jan Mach{\'a}\v{c}ek%$^{1}$% <-this % stops a space
\thanks{Supported by Cake Solutions Limited}% <-this % stops a space
\thanks{$^{1}$J. Machacek is the CTO at Cake Solutions, Houldsworth Mill, Houldsworth Street, Reddish, SK5 6DA, UK {\tt\small janm at cakesolutions.net}}%
}

\begin{document}

\twocolumn[
  \begin{@twocolumnfalse}
    \maketitle
    \begin{abstract}
      
    \end{abstract}
  \end{@twocolumnfalse}
]

\section{Composition}
Composition is a way of combining several smaller units of functionality to build larger ones. It does not prescribe any particular programming style: calling other functions from a functions is compisition, so is dependency injection in traditional OO world.

To demonstrate, consider an order processing system that fulfils the order contained within a request by decoding the order data from the request, calculates discounts and books the best delivery method, before finalising the order and encoding it into a response can compute the discount and delivery method at the same time (to use a loose term for now), though the other operations must be sequential; see \autoref{fig:order-fulfilment}.

\begin{figure}[h]
  \DontPrintSemicolon
  
  \[ 
    decode \rightwavearrow
    \left \{\begin{array}{l}
      delivery \\ discount
      \end{array}
    \right \} \rightwavearrow finalise \rightwavearrow encode
  \]
  \caption{Order fulfilment}
  \label{fig:order-fulfilment}
\end{figure} 

This type of processing is a typical result of decomposing the \emph{order fulfilment} into its steps. The decomposition and the algorithm assume that the entire fulfilment operation is atomic and that its effects on the world are completely isolated until the \pcode{encode} operation successfully completes. 

\subsection{Serial and pure implementation}
It is easiest to start exploring the problem using an imperative pseudo-code in \autoref{code:fulfilment-impl-1}.

\begin{lstlisting}[caption={Fulfilment implementation I}, label={code:fulfilment-impl-1}, language=Pseudo, escapechar=|]
order = decode(request)
delivery = delivery(order)
discount = discount(order)
fulfiled = finalise(order, delivery, discount)
response = encode(fulfiled)
\end{lstlisting}

This code is an accurate representation of the process when the \pcode{decode}, \pcode{delivery}, \pcode{discount}, \pcode{finalise}, and \pcode{encode} functions are pure: the functions' results depend only on the values given as parameters; their types are \pcode{I => O} for the appropriate types \pcode{I} and \pcode{O}. (The type of the \pcode{decode} function, for example, is \pcode{Request => Order}). In this order fulfilment system, the ``business'' functions need to interact with the world to arrive at their result. 

In some very popular languages (cite: Java, C\#) it is not possible to define plain functions: every function needs to be part of a class\footnote{\pcode{class} means template for instances.}. Even though it is possible to define \pcode{static} method in these languages, where the method can be invoked without creating an instance of the class--and thus treating the class containing the static method as a namespace--it is usual to define and use interfaces that define the beaviour\cite{prospring}. This yields code in \autoref{code:fulfilment-impl-oo}.

\begin{lstlisting}[caption={Fulfilment OO implementation I}, label={code:fulfilment-impl-oo}, language=Java, escapechar=|]
interface OrderCodec {
  Order decode(Request r);
  Response encode(Order o);
}
interface DeliveryBookingService {
  Delivery book(Order o);
}
interface DiscountCalculatorService {
  Discount calculate(Order o);
}
interface OrderFinalisationService {
  Fulfiled finalise(Order o, 
                    Delivery del, 
                    Discount dis);
}
\end{lstlisting}

This is almost mechanical wrapping of the naked functions into interfaces; the implementations of these interfaces contain the code that the naked functions contained. The code from \autoref{code:fulfilment-impl-1} then becomes part of another class in \autoref{code:fulfilment-impl-oo2}.

\begin{lstlisting}[caption={Fulfilment OO implementation II}, label={code:fulfilment-impl-oo2}, language=Java, escapechar=|]
interface Fulfilment {
  Response fulfil(Request request);
}
class FulfilmentImpl implements Fulfilment {
  OrderCodec oc;
  DeliveryBookingService dbs;
  DiscountCalculatorService dcs;
  OrderFinalisationService ofs;

  Response fulfil(Request request) {
    var order = oc.decode(request);
    var delivery = dbs.book(order);
    var discount = dcs.calculate(order);
    var fulfiled = ofs.finalise(
      order, delivery, discount);
    return oc.encode(fulfiled);
  }
}
\end{lstlisting}

The \pcode{Fulfilment} \emph{composes} the sub-components (\pcode{OrderCodec}, \pcode{DeliveryBookingService} and others) into a larger unit. The interface \pcode{Fulfilment} hides all the complexity of the processing; the implementation \pcode{FulfilmentImpl} delegates the work to its sub-components. The code in \autoref{code:fulfilment-impl-oo2} omits the construction of these components. The usual approach is to avoid having the \pcode{OrderHandlerImpl} be responsible for creating its dependencies to keep to the single-responsibility principle; so the \pcode{OrderHandlerImpl} must be given these dependencies at the point of its construction. It becomes 

\begin{lstlisting}[caption={Fulfilment OO implementation II}, label={code:fulfilment-impl-oo3}, language=Java, escapechar=|]
interface Fulfilment {
  Response fulfil(Request request);
}
class FulfilmentImpl implements Fulfilment {
  private final OrderCodec oc;
  private final DeliveryBookingService dbs;
  private final DiscountCalculatorService dcs;
  private final OrderFinalisationService ofs;

  FulfilmentImpl(
    OrderCodec oc, 
    DeliveryBookingService dbs,
    DiscountCalculatorService dcs,
    OrderFinalisationService ofs) {
    this.oc = oc;
    this.dbs = dbs;
    this.dcs = dcs;
    this.ofs = ofs;
  }

  Response fulfil(Request request) { ... }
}
\end{lstlisting}

In large systems, the construction of all components--each with its own chain of dependencies--becomes tedious. The tedious work of manual construction of all components might even slow down any refactoring that affects the construction graph. An alternative approach is to use dependency injection pattern: a DI framework maintains an environment of all constructed / constructible components. When a new component needs to be added into this environment, the framework satisfies its dependencies (expressed through constructor parameters, setters, or using some other mechanism), registeres the newly created component in the environment, and returns the registered instance. This way, the code that makes up the components looks like plain Java, but the components are implicitly tied to this environment maintained by the DI framework. This low-level composition is comfortable; it is also accurate representation of our initial decomposition if the methods in the components are still pure. The \pcode{FulfilmentImpl.fulfil} remains pure if the components injected at the point of construction do not change throughout the life of the system and if their methods are pure. 

\subsection{Effects}
\emph{Useful systems exist only for their side-effects.}

The \pcode{delivery} function (or the \pcode{DeliveryBookingService.book} method) needs to call various couriers' APIs to select \& book the best one; the \pcode{discount} function needs to query an affiliate database for possible price reduction; the \pcode{finalise} function needs to make further external API calls and database operations. The only functions that remain as pure are \pcode{decode} and \pcode{decode}. If the implementation uses a DI framework, the database connection or the API clients are injected into the components; the injected dependencies do not change, but their methods are not pure. Many programming languages \& runtimes use exceptions as a way to keep the functions' types intact, but to provide a mechanism to indicate that the purity abstraction has leaked. In Java, one might implement the \pcode{delivery} function as \pcode{Delivery book(Request r) throws DeliveryException}, where the \pcode{DeliveryException} is a root of an inheritance hierarchy of more detailed exceptions. The callers are then responsible for handling any raised exceptions. The usual code is in \autoref{code:fulfilment-impl-exc}.

\begin{lstlisting}[caption={Exceptions}, label={code:fulfilment-impl-exc}, language=Java, escapechar=|]
DeliveryBookingService dbs = ...;
Order o = ...;
try {
  dbs.book();
} catch (DeliveryException ex) {
  |oops, not booked; maybe we retry?|
}
\end{lstlisting}

The devil is in the detail: the code in \autoref{code:fulfilment-impl-exc} assumes that the \pcode{DeliveryBookingService.book} is isolated and atomic; an exception arising from the call means that everything that the \pcode{DeliveryBookingService.book} has done has been undone. Abandoning inheritance hierarchy of exceptions provides partial solution. Remove the \pcode{DeliveryException} superclass and have the method throw--for example--\pcode{DeliveryAPIUnavailable}, \pcode{DeliveryRejected}, and \pcode{DeliveryBookingTimeout}. The \pcode{catch} block becomes longer, but has the opportunity to handle specific error cases. Unfortunately, in Java and C\#, all exceptions must implement the \pcode{Throwable} interface. This, combined with the fact that writing long \pcode{catch} blocks is tedious, leads to shortcuts. Instead of exhaustive error handling in \autoref{code:fulfilment-impl-exc2}...

\begin{lstlisting}[caption={Exceptions}, label={code:fulfilment-impl-exc2}, language=Java, escapechar=|]
DeliveryBookingService dbs = ...;
Order o = ...;
try {
  dbs.book();
} catch (DeliveryAPIUnavailable ex) { 
  |Retryable, nothing to undo|
} catch (DeliveryRejected ex) {
  |Not retryable, but nothing to undo|
} catch (DeliveryBookingTimeout ex) {
  |Has the other system received the request and|
  |failed to respond, or has the request not reached|
  |the other system at all?|
}
\end{lstlisting}

...the code [ab]uses the root exception hierarchy imposed by the language and ends up as \autoref{code:fulfilment-impl-exc3}.

\begin{lstlisting}[caption={Exceptions}, label={code:fulfilment-impl-exc3}, language=Java, escapechar=|]
DeliveryBookingService dbs = ...;
Order o = ...;
try {
  dbs.book();
} catch (Exception ex) { 
  |An unexpected error has occurred. Do you feel lucky?|
}
\end{lstlisting}

Unfortunately, exceptions are not sufficient to express the richness of the possible failures that can happen with code that relies on side-effects, and the abstraction of purity in the world of side-effects leaks. The immediate and hard errors can be expressed with exceptions: the \pcode{connection denied} or \pcode{illegal argument exception} are expressive enough and can be raised without any delays. Detecting and raising a \pcode{request timeout} exception takes more time; during this time, the thread of execution must be blocked. 

\subsection{Concurrency and parallelism}
The world is concurrent, and parts of the world can be parallel. Concurrency means many different things happening at the same time: think different users making requests to the order fulfilment system. Parallellism means splitting larger unit of work into smaller independent units of work and then combining their result: think vector dot product running on a GPU, where each multiplication is independent of the other and runs on a different GPU core. 

% A useful and almost leak-less abstraction is imagine that a serial process is self-contained unit which proceeds one instruction at a time and has immediate and consistent view of its memory. A concurrent process proceeds ``many instructions at the same time'', making consistent view of its memory difficult. Because concurrent process proceeds ``many instructions at the same time'' it needs to synchronise access to its memory in order for all its instructions to see the ``same'' values. 

When two concurrent processes do not need to communicate with each other they proceed in parallel; when two concurrent processes have to communicate, it is necessary to understand the mechanism of the communication to be able to build error-free programs. A typical error in concurrent programs is unsynchronised access to a shared state: the processes \pcode{oneStepForward} and \pcode{oneStepBack} both access the same shared \pcode{state} in \autoref{code:concurrent-1}.

\begin{lstlisting}[caption={Shared mutable state}, label={code:concurrent-1}, language=Pseudo, escapechar=|]
|The shared mutable state|
state = 0

|The processes that mutate the state|
oneStepForward = state += 1
oneStepBack = state -= 1

|Threads provide mechanism to run the two processes concurrently|
startThread(oneStepForward)
startThread(oneStepBack)

|The parent process collects the result|
if state != 0 then output(state)
\end{lstlisting}

The value passed to the \pcode{output} call is not deterministic; and it can even be zero, because the \pcode{state != 0} condition evaluates to \pcode{true}, but then one of the threads mutates the \pcode{state}, but the code is already following the ``then'' branch. The concurrent processes need to synchronise access and mutation to the shared state. (Viz \autoref{code:concurrent-2})

\begin{lstlisting}[caption={Locked shared mutable state}, label={code:concurrent-2}, language=Pseudo, escapechar=|]
|The shared mutable state|
state = 0
|The lock that only allows one process to enter|
lock = makeLock

|The processes acquire and release the lock|
oneStepForward = with(lock) { state += 1 }
oneStepBack = with(lock) { state -= 1 }

...

|The parent also locks on the state|
with(lock) {
  if state != 0 then output(state)
}
\end{lstlisting}

The value of \pcode{state} in program in \autoref{code:concurrent-2} isn't deterministic because the order order in which the concurrent processes \pcode{oneStepForward} and \pcode{oneStepBack} are selected to run isn't determined, but the locks ensure that the state doesn't change while one particular process is using it. The size of the program is small enough to be able to reason about the concurrent processes; just as importantly, the program is running on a single machine and state is in memory on the same machine. A single machine provides almost leak-free abstraction of reliable computation and immediate memory access.

This still isn't a problem until two processes need to communicate to reach agreement on some state, or to cooperate in computation. 



Changing the type \pcode{O} to higher-kinded type $\mathds{F}$ provides a way to express that the returned value is not the raw value of type \pcode{O}, but that it is wrapped in some container $\mathds{F}$. For $\mathds{F} = Future$, \pcode{decode(Request): Order} becomes \pcode{decode(Request): Future[[Order]]}, which expresses the fact that the result of applying these functions to the input does not yield the result immediately; it \emph{starts} the computation and returns the conainer $\mathds{F} = Future$ which will hold the computed value. Viz \autoref{code:fulfilment-impl-2}.

\begin{lstlisting}[caption={Fulfilment implementation II}, label={code:fulfilment-impl-2}, language=Pseudo, escapechar=|, escapeinside={(*}{*)}]
order = decode(request)
(delivery, discount) <- delivery(order) 
                     (*$\curlywedge$*) discount(order)
fulfiled <- finalise(order, delivery, discount)
response = encode(fulfiled)
\end{lstlisting}

The only difference between the two listings is the changing of assignment operator \pcode{=} to the sequence / shove operator \pcode{<-}; and the usage of the $\curlywedge$ operator to ``zip'' two $\mathds{F}$s together: $\mathds{F}\lBrack{}A\rBrack \curlywedge \mathds{F}\lBrack{}B\rBrack \Rightarrow \mathds{F}\lBrack(A, B)\rBrack$. This changes the type of \pcode{order} to \pcode{Future[[Order]]}, the type of \pcode{delivery} to \pcode{Future[[Delivery]]}, \ldots, the type of \pcode{response} to \pcode{Future[[Response]]}. It is possible to \emph{compose} the components that deal with decoding, booking delivery, computing a discount, finalising, and encoding to a larger component of type \pcode{Request => Future[[Response]]}.

% decode(request).flatMap { order =>
%   delivery(order).zip(discount(order))
%     .flatMap { (delivery, discount) =>
%       finalise(order, delivery, discount)
%     }
%     .flatMap { fulfiled => 
%       encode(fulfiled) 
%     }
% }

The \pcode{Future} can succeed or fail, making the code in \autoref{code:fulfilment-impl-2} feel right. The code does not handle any failures

The fulfilment operation isn't instant, and the world does not stop while it is processing. If the entire fulfilment operation could be done in the same memory and by only affecting that memory, it would be possible to use software transactional memory\cite{stm}. If the decomposed steps in the fulfilment process change the world (by initiating network communication, by printing labels, etc.) they cannot be simply retried: is it OK to make a delivery booking twice?; is it acceptable to print the packaging label multiple times? Deduplicating non-idempotent requests encounters storage limits: any deduplicating code can only deduplicate on a fixed number of requests. Locking reduces the throughput of a system as the number of locks grows: locking code has to be able to old locks. 

Even if isolation and atomicity were achievable in the context of this system, the \pcode{delivery} booking system might not be able to participate in any form of transaction. Worse still, the \pcode{delivery} booking step might have returned a successful booking, but by the time the \pcode{finalise} step executes, the delivery booking becomes invalid.

encode can fail.

DeliveryEstimate: Order => Days

Discount: Order => Days

Fulfilment(deliveryEstimate, discount): Order => Fulfilment =
  order =>
    deliveryEstimate(order) and discount(order)

\emph{Pure} actors do not compose. 


\section{Ramblings \& notes}
Asynchrony and concurrency is difficult; it is tempting to dismiss it as \emph{too complicated} for applications that ``simply'' take a request and produce a response, where the work to produce the response involves simple data transformations and straight-forward logic.

\begin{lstlisting}[caption={Delivery estimate}, label={code:delivery-estimate}, language=Pseudo, escapechar=|]
|The actual business logic that computes the delivery estimate for|
|the given item|
deliveryEstimate(item: Item): Days

|Mechanics for transforming between the request and response and|
|the application's data model|
fromRequest(request: Request): Order
toResponse(estimate: Days): Response

|The main handling code that computes the delivery estimate for|
|the order in the request, producing the estimate in the response|
handle(request: Request): Response = 
  items    <- parseItems(request)
  estimate <- 0
  for (item in items) {
    e <- deliveryEstimate(item)
    if (e > estimate) estimate = e
  }
  return toResponse(estimate)
}
\end{lstlisting}

If the \pcode{deliveryEstimate} function is \emph{pure} (its result depends only on the given parameter and nothing else) making the \pcode{handle} function also pure, then it would appear that this code is a perfect candidate to use a thread-per-request model and not worry about any concurrency at all. The answer depends on how the application gets the \pcode{Request} and where the \pcode{Response} ends up\footnote{I am not going to follow the rabbit hole of layering in more and more pure functions: programs run to interact with the world by the means of impure I/O. However, I do not dismiss purity or the ability to track the spread of arbitrary effects such as I/O.}, how many requests the application handles concurrently, what response time guarantees the application makes, and on the underlying implementation of the thread of execution.

Given $N_{t}$ number of threads and $N_{r}$, there are the following scenarios:

* $N_{r} \ll N_{t}$ and low response time critical

* $N_{r} \le N_{t}$ 

* $N_{r} > N_{t}$

* $N_{r} \gg N_{t}$

Thread-per-request model works if the delivery estimate module is used by another module that is also pure (see \autoref{code:delivery-estimate-and-discount})

\begin{lstlisting}[caption={Delivery and discount}, label={code:delivery-estimate-and-discount}, language=Pseudo, escapechar=|]
|The delivery estimate module with its specific handle function|
module DeliveryEstimate =
  handle(request: Request): Response

|The discount module with its specific handle function|
module Discount =
  handle(request: Request): Response

toResponse(r1: DeliveryEstimate.Response,
           r2: Discount.Response): Response
handle(request: Request): Response = 
  r1 <- DeliveryEstimate.handle(request)
  r2 <- Discount.handle(request)
  return toResponse(r1, r2)

\end{lstlisting}


State machine model of computation has to have bounded non-determinism; the configuraiton model of computation (i.e. actors; with local state and communication) does not have a bound on non-determinism, because it incorporates communication; we have indeterminism.

[Pure] functions are data, because every function can be replaced by a table of data and some generic look-up code. For efficiency, $\sin x$ can be implemented as a very large table for [almost] every value of $x$. The body of the funciton is then not the computation of $\sin x$, but of \pcode{data = (0 -> 0), (0.1 -> 0.0998), (0.2 -> 0.1987), ..., (M_PI/2 -> 1)} and lookup that finds the value in the table for the argument. It is possible to construct this table for every pure function.


\section{Actors}
There are many actor frameworks and toolkits\cite{akka,scalaz8,transient,thespian}. Some toolkits make it very difficult to compose the behaviour of the actors\cite{akka,thespian}, other toolkits make it much easier\cite{scalaz8,transient}. I consider the actor model as a way to \emph{decompose} a system into self-contained units of functionality and state. I consider these units of functionality and state to be the smallest deployable entities; consequently, the communication between two actors must take form of messages travelling over a boundary that introduces latency and the risk of message loss. Given this definition, it does not make sense to require convenient general composition mechanism for general actors. Such composition mechanism is an abstraction that must attempt to hide the underlying latency and the risk of message loss\footnote{Consider the \emph{Network File System}, which abstracts over unreliable networks to provide the illusion that a filesystem on a remote machine is the same as the filesystem on the local machine. The abstraction \emph{leaks} when the network is slow or lossy, when a lot of small files are being accessed over the network, when a different application generates a lot of traffic on the NIC that also handles the NFS mount, etc.}. 


\printbibliography

\end{document}